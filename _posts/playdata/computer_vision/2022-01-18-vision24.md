---
layout : single
title: "지역 특징점 검출과 매칭(3)"
excerpt : "기하학적 변환된 영상에 키포인트 검출 적용"
categories :
- Computer Vision
tags :
- [Playdata , Python, OpenCV, Computer Vision]
toc: true #Table of contents 옆에 목록이 생성됨
toc_sticky: true #toc가 화면을 따라 내려옴
toc_label: 목차 #toc 상단에 써있는 제목

date: 2022-01-18
last_modified_at: 2022-01-18
---

기하학적 변환 및 다양한 변화가 적용된 이미지의 특징점 매칭

## Original Image 확인하기

```
import matplotlib.pyplot as plt
src = cv2.imread('./data/face.jpeg')

src_rgb = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)
gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)

plt.subplot(121)
plt.title("rgb image")
plt.imshow(src_rgb)
plt.subplot(122)
plt.title("gray")
plt.imshow(gray , cmap = "gray")
```

<div style="text-align:center;">
<img src="/assets/post_photo/opencv/key8.jpg" width="60%">
</div>

## 키포인트 검출하기

```
plt.rcParams["figure.figsize"] = [14, 7]

orb = cv2.ORB_create(1000,2)
keypoints, descriptor = orb.detectAndCompute(gray,None)
dst1 = cv2.drawKeypoints(src_rgb,keypoints,None,(0,255,0))
dst2 = cv2.drawKeypoints(src_rgb,keypoints,None,(-1,-1,-1),flags = cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)

plt.subplot(121)
plt.title("dst1")
plt.imshow(dst1)

plt.subplot(122)
plt.title("dst2")
plt.imshow(dst2)
```

<div style="text-align:center;">
<img src="/assets/post_photo/opencv/key9.jpg" width="60%">
</div>

## Descriptor ( binary feature vector ) 매칭하기

```
plt.rcParams["figure.figsize"] = [14, 7]

src1 = cv2.imread('./data/face.jpeg')
src2 = cv2.imread('./data/face.jpeg')

src_rgb1 = cv2.cvtColor(src1, cv2.COLOR_BGR2RGB)
src_rgb2 = cv2.cvtColor(src2, cv2.COLOR_BGR2RGB)

plt.subplot(121)
plt.title("src_rgb1")
plt.imshow(src_rgb1)

query = cv2.cvtColor(src1, cv2.COLOR_BGR2GRAY)
train = cv2.cvtColor(src2, cv2.COLOR_BGR2GRAY)

orb = cv2.ORB_create(1000, 2) # keypoint의 갯수, scale factor

train_keypoints, train_descriptor = orb.detectAndCompute(train,None)
query_keypoints, query_descriptor = orb.detectAndCompute(query,None)

print("[train] len(keypoints) : ",len(train_keypoints))
print("[train] descriptor.shape : ",train_descriptor.shape)

print("[query] len(keypoints) : ",len(query_keypoints))
print("[query] descriptor.shape : ",query_descriptor.shape)

matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING, crossCheck=True) #True
matches = matcher.match(train_descriptor, query_descriptor)

sorted_matches = sorted(matches, key=lambda x:x.distance)
good_matches = sorted_matches[:200]

# matches 의 순서랑 같게 해야한다.
dst = cv2.drawMatches(train, train_keypoints, query, query_keypoints, good_matches, None,
                      flags = cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)


plt.subplot(122)
plt.title("Best Matchin Result")
plt.imshow(dst)
plt.show()
```

<div style="text-align:center;">
<img src="/assets/post_photo/opencv/key10.jpg" width="70%">
</div>
<br />

## Scale Invariance

```
plt.rcParams["figure.figsize"] = [14, 7]

src1 = cv2.imread('./data/faceQS.png')
src2 = cv2.imread('./data/face.jpeg')

src_rgb1 = cv2.cvtColor(src1, cv2.COLOR_BGR2RGB)
src_rgb2 = cv2.cvtColor(src2, cv2.COLOR_BGR2RGB)

plt.subplot(121)
plt.title("src_rgb1")
plt.imshow(src_rgb1)

query = cv2.cvtColor(src1, cv2.COLOR_BGR2GRAY)
train = cv2.cvtColor(src2, cv2.COLOR_BGR2GRAY)

orb = cv2.ORB_create(1000, 2) # keypoint의 갯수, scale factor

train_keypoints, train_descriptor = orb.detectAndCompute(train,None)
query_keypoints, query_descriptor = orb.detectAndCompute(query,None)

print("[train] len(keypoints) : ",len(train_keypoints))
print("[train] descriptor.shape : ",train_descriptor.shape)

print("[query] len(keypoints) : ",len(query_keypoints))
print("[query] descriptor.shape : ",query_descriptor.shape)

matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING, crossCheck=True) #True
matches = matcher.match( query_descriptor,train_descriptor)

sorted_matches = sorted(matches, key=lambda x:x.distance)
good_matches = sorted_matches[:200]

dst = cv2.drawMatches( query, query_keypoints,train, train_keypoints, good_matches, None,
                      flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS) # 매칭되지 않은 keypoint는 표시하지 않음

plt.subplot(122)
plt.title("Best Matchin Result")
plt.imshow(dst)
plt.show()
```

<div style="text-align:center;">
<img src="/assets/post_photo/opencv/key11.jpg" width="60%">
</div>

## Rotational Invariance

```
plt.rcParams["figure.figsize"] = [14, 7]

src1 = cv2.imread('./data/faceR.jpeg')
src2 = cv2.imread('./data/face.jpeg')

src_rgb1 = cv2.cvtColor(src1, cv2.COLOR_BGR2RGB)
src_rgb2 = cv2.cvtColor(src2, cv2.COLOR_BGR2RGB)

plt.subplot(121)
plt.title("src_rgb1")
plt.imshow(src_rgb1)
plt.subplot(122)
plt.title("src_rgb2")
plt.imshow(src_rgb2)
plt.show()

query = cv2.cvtColor(src1, cv2.COLOR_BGR2GRAY)
train = cv2.cvtColor(src2, cv2.COLOR_BGR2GRAY)

orb = cv2.ORB_create(1000, 2) # keypoint의 갯수, scale factor

train_keypoints, train_descriptor = orb.detectAndCompute(train,None)
query_keypoints, query_descriptor = orb.detectAndCompute(query,None)

print("[train] len(keypoints) : ",len(train_keypoints))
print("[train] descriptor.shape : ",train_descriptor.shape)

print("[query] len(keypoints) : ",len(query_keypoints))
print("[query] descriptor.shape : ",query_descriptor.shape)

matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING, crossCheck=True) #True
matches = matcher.match( query_descriptor,train_descriptor)

sorted_matches = sorted(matches, key=lambda x:x.distance)
good_matches = sorted_matches[:200]

dst = cv2.drawMatches( query, query_keypoints,train, train_keypoints, good_matches, None,
                      flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS) # 매칭되지 않은 keypoint는 표시하지 않음

plt.subplot(121)
plt.title("Best Matchin Result")
plt.imshow(dst)
plt.show()
```

<div style="text-align:center;">
<img src="/assets/post_photo/opencv/key12.jpg" width="60%">
<img src="/assets/post_photo/opencv/key13.jpg" width="60%">
</div>

## Illuminaion(조명) Invariance

```
plt.rcParams["figure.figsize"] = [14, 7]

src1 = cv2.imread('./data/faceRI.png')
src2 = cv2.imread('./data/face.jpeg')

src_rgb1 = cv2.cvtColor(src1, cv2.COLOR_BGR2RGB)
src_rgb2 = cv2.cvtColor(src2, cv2.COLOR_BGR2RGB)

plt.subplot(121)
plt.title("src_rgb1")
plt.imshow(src_rgb1)
plt.subplot(122)
plt.title("src_rgb2")
plt.imshow(src_rgb2)
plt.show()

query = cv2.cvtColor(src1, cv2.COLOR_BGR2GRAY)
train = cv2.cvtColor(src2, cv2.COLOR_BGR2GRAY)

orb = cv2.ORB_create(1000, 2) # keypoint의 갯수, scale factor

train_keypoints, train_descriptor = orb.detectAndCompute(train,None)
query_keypoints, query_descriptor = orb.detectAndCompute(query,None)

print("[train] len(keypoints) : ",len(train_keypoints))
print("[train] descriptor.shape : ",train_descriptor.shape)

print("[query] len(keypoints) : ",len(query_keypoints))
print("[query] descriptor.shape : ",query_descriptor.shape)

matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING, crossCheck=True) #True
matches = matcher.match( query_descriptor,train_descriptor)

sorted_matches = sorted(matches, key=lambda x:x.distance)
good_matches = sorted_matches[:200]

dst = cv2.drawMatches( query, query_keypoints,train, train_keypoints, good_matches, None,
                      flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS) # 매칭되지 않은 keypoint는 표시하지 않음

plt.subplot(121)
plt.title("Best Matchin Result")
plt.imshow(dst)
plt.show()
```

<div style="text-align:center;">
<img src="/assets/post_photo/opencv/key14.jpg" width="60%">
<img src="/assets/post_photo/opencv/key15.jpg" width="60%">
</div>

## Noise Invariance

```
plt.rcParams["figure.figsize"] = [14, 7]

src1 = cv2.imread('./data/faceRN5.png')
src2 = cv2.imread('./data/face.jpeg')

src_rgb1 = cv2.cvtColor(src1, cv2.COLOR_BGR2RGB)
src_rgb2 = cv2.cvtColor(src2, cv2.COLOR_BGR2RGB)

plt.subplot(121)
plt.title("src_rgb1")
plt.imshow(src_rgb1)
plt.subplot(122)
plt.title("src_rgb2")
plt.imshow(src_rgb2)
plt.show()

query = cv2.cvtColor(src1, cv2.COLOR_BGR2GRAY)
train = cv2.cvtColor(src2, cv2.COLOR_BGR2GRAY)

orb = cv2.ORB_create(1000, 2) # keypoint의 갯수, scale factor

train_keypoints, train_descriptor = orb.detectAndCompute(train,None)
query_keypoints, query_descriptor = orb.detectAndCompute(query,None)

print("[train] len(keypoints) : ",len(train_keypoints))
print("[train] descriptor.shape : ",train_descriptor.shape)

print("[query] len(keypoints) : ",len(query_keypoints))
print("[query] descriptor.shape : ",query_descriptor.shape)

matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING, crossCheck=True) #True
matches = matcher.match( query_descriptor,train_descriptor)

sorted_matches = sorted(matches, key=lambda x:x.distance)
good_matches = sorted_matches[:200]

dst = cv2.drawMatches( query, query_keypoints,train, train_keypoints, good_matches, None,
                      flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS) # 매칭되지 않은 keypoint는 표시하지 않음

plt.subplot(121)
plt.title("Best Matchin Result")
plt.imshow(dst)
plt.show()
```

<div style="text-align:center;">
<img src="/assets/post_photo/opencv/key16.jpg" width="60%">
<img src="/assets/post_photo/opencv/key17.jpg" width="60%">
</div>

## Object Detection

```
plt.rcParams["figure.figsize"] = [14, 7]

img1 = cv2.imread('./data/Team.jpeg')
img2 = cv2.imread('./data/face.jpeg')


img1_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)
img2_rgb = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)

plt.subplot(121)
plt.title("img1_rgb")
plt.imshow(img1_rgb)

plt.subplot(122)
plt.title("img2_rgb")
plt.imshow(img2_rgb)
plt.show()
```

<div style="text-align:center;">
<img src="/assets/post_photo/opencv/key18.jpg" width="70%">
</div>

```
plt.rcParams["figure.figsize"] = [34, 34]

query = cv2.cvtColor(img2_rgb, cv2.COLOR_BGR2GRAY)
train = cv2.cvtColor(img1_rgb, cv2.COLOR_BGR2GRAY)

orb = cv2.ORB_create(5000, 2) # keypoint의 갯수, scale factor

query_keypoints, query_descriptor = orb.detectAndCompute(query, None)
train_keypoints, train_descriptor = orb.detectAndCompute(train, None)

print("[query] len(keypoints)", len(query_keypoints))
print("[query] descriptor.shape", query_descriptor.shape)

print("[train] len(keypoints)", len(train_keypoints))
print("[train] descriptor.shape", train_descriptor.shape)

matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING, crossCheck=True) #True
matches = matcher.match(query_descriptor, train_descriptor)

sorted_matches = sorted(matches, key=lambda x: x.distance)
good_matches = sorted_matches[:90]


dst = cv2.drawMatches(query, query_keypoints, train, train_keypoints, good_matches, None,
                      flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS) # 매칭되지 않은 keypoint는 표시하지 않음


plt.subplot(121)
plt.title("Best Matchin Result")
plt.imshow(dst)
plt.show()
```

<div style="text-align:center;">
<img src="/assets/post_photo/opencv/key19.jpg" width="70%">
</div>
